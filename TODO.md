## `TODO.md`


```markdown
# TODO — MNIST Neural Network (Scratch)


## High Priority
-  Implement parameter initialization (`W1`, `b1`, `W2`, `b2`).
-  Forward propagation with ReLU and softmax.
-  Compute cost function (cross‑entropy loss).
-  Backpropagation implementation.
-  Training loop with gradient descent.


## Medium Priority
-  Add accuracy calculation function.
-  Implement mini‑batch training instead of full batch.
-  Save model parameters (pickle).
-  Plot cost curve per epoch.


## Low Priority
-  Visualize misclassified digits.
-  Experiment with deeper networks (>2 layers).
-  Add dropout/regularization.
-  Benchmark against scikit‑learn LogisticRegression baseline.
